{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# USCS Academic Research - MARINe Site Visualisation Notebook\n",
        "- Weijie Yang\n",
        "- Jenna Sparks"
      ],
      "metadata": {
        "id": "bACRiSPdtjb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Import necessary packages"
      ],
      "metadata": {
        "id": "8SNpMaeNtzIn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1uh1UG6b2i2",
        "outputId": "3a1a6f38-4c2f-4ae5-cfe5-89f8c73a90f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyecharts\n",
            "  Downloading pyecharts-2.0.4-py3-none-any.whl (147 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/147.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m112.6/147.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.7/147.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyecharts) (3.1.2)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from pyecharts) (3.9.0)\n",
            "Collecting simplejson (from pyecharts)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyecharts) (2.1.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->pyecharts) (0.2.10)\n",
            "Installing collected packages: simplejson, pyecharts\n",
            "Successfully installed pyecharts-2.0.4 simplejson-3.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pyecharts\n",
        "import pandas as pd\n",
        "from pyecharts.charts import Bar, Grid, Line, Page, Pie\n",
        "from pyecharts.charts import ThemeRiver\n",
        "from pyecharts.globals import ThemeType\n",
        "from pyecharts.charts import Map3D\n",
        "from pyecharts.commons.utils import JsCode\n",
        "from pyecharts.globals import ChartType, SymbolType\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import numpy as np\n",
        "import pyecharts.options as opts\n",
        "from pyecharts.charts import Surface3D\n",
        "from pyecharts.charts import Scatter3D\n",
        "from pyecharts.charts import Page\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Load dataset"
      ],
      "metadata": {
        "id": "vSceM9oZuEmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import downloaded file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "xURx6lsDpCHt",
        "outputId": "3b285745-cb1f-410a-cb55-a3bd43cbc05d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4a0f9a08-736c-4e12-b940-bc5d74a6c393\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4a0f9a08-736c-4e12-b940-bc5d74a6c393\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ddiscovery_elevation_data_update_20231108.xlsx to ddiscovery_elevation_data_update_20231108.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load species data\n",
        "df = pd.read_excel(\"ddiscovery_elevation_data_update_20231108.xlsx\", sheet_name=\"point_contact_per_cover\")\n",
        "# reformat df\n",
        "df = df.rename(columns={'marine_site_name': 'intertidal_sitename', 'latitude': 'site_latitude', 'longitude': 'site_longitude'})\n",
        "# Group df by 'intertidal_sitename'\n",
        "grouped_data = df.groupby('intertidal_sitename')"
      ],
      "metadata": {
        "id": "0IA_cbx5W_Ex"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset for surface map\n",
        "elevation_df = pd.read_excel(\"ddiscovery_elevation_data_update_20231108.xlsx\",sheet_name=\"elevation_data\")\n",
        "species_df = pd.read_excel(\"ddiscovery_elevation_data_update_20231108.xlsx\",sheet_name=\"species_heights\")"
      ],
      "metadata": {
        "id": "Sf0NZ2rbps8-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Establish functions for each visualization\n"
      ],
      "metadata": {
        "id": "pbuZPsIbuSoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diagram - Surface Map\n",
        "- Display the surface of the site in the latest year & species distributions"
      ],
      "metadata": {
        "id": "ElNGTZ8qvAou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def surface(elevation_df, species_df, site_name):\n",
        "  # processing dataset\n",
        "  elevation_df = elevation_df.loc[elevation_df[\"intertidal_sitename\"] == site_name]\n",
        "  # Trim out \"Other Species\"\n",
        "  species_df = species_df.loc[species_df[\"species_lump\"] != \"Other Species\"]\n",
        "  species_df = species_df.loc[species_df[\"intertidal_sitename\"] == site_name]\n",
        "  species_df = species_df.loc[species_df[\"year\"] == max(species_df[\"year\"].tolist())] # get the latest year's species\n",
        "  elevation_df = elevation_df[[\"intertidal_sitename\",\"section\",\"x_transect\",\"location\",\"Mean(z_rock_height)\"]]\n",
        "  species_df = species_df[[\"intertidal_sitename\",\"section\",\"x_transect\",\"location\",\"Mean(z_rock_height)\",\"species_lump\"]]\n",
        "  input_df = pd.merge(left = elevation_df, right = species_df, on = [\"section\",\"x_transect\",\"location\",\"Mean(z_rock_height)\"], how = \"left\", indicator = False)\n",
        "\n",
        "  # identify whether there are two sections\n",
        "  if len(set(input_df[\"section\"].tolist())) == 1:\n",
        "    # only one section\n",
        "    surface_df = input_df[[\"location\",\"x_transect\",\"Mean(z_rock_height)\"]]\n",
        "    data_pair = np.array(surface_df).tolist()\n",
        "    # === Create Surface\n",
        "    surface = Surface3D()\n",
        "    surface.add(\n",
        "        series_name=\"Surface of \"+ site_name,\n",
        "        shading=\"color\",\n",
        "        data=data_pair,\n",
        "        xaxis3d_opts=opts.Axis3DOpts(type_=\"value\",name=\"X Transect\"),\n",
        "        yaxis3d_opts=opts.Axis3DOpts(type_=\"value\",name=\"Y Location\"),\n",
        "        zaxis3d_opts=opts.Axis3DOpts(type_='value',name='Mean(z_rock_height)'),\n",
        "        grid3d_opts=opts.Grid3DOpts(width=100, height=40, depth=100),\n",
        "    )\n",
        "    surface.set_global_opts(\n",
        "        title_opts=opts.TitleOpts(title=\"Surface Chart - \" + site_name),\n",
        "        visualmap_opts=opts.VisualMapOpts(\n",
        "            dimension=2,\n",
        "            max_=surface_df[\"Mean(z_rock_height)\"].max(),\n",
        "            min_=surface_df[\"Mean(z_rock_height)\"].min(),\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "    # === species data\n",
        "    distribution_df = input_df.copy()\n",
        "    distribution_df.sort_values(by=\"species_lump\")\n",
        "    spec_lst = list(set([i for i in distribution_df[\"species_lump\"]]))\n",
        "    if np.nan in spec_lst:\n",
        "      spec_lst.remove(np.nan)\n",
        "    data_dict = {}\n",
        "    for i in spec_lst:\n",
        "        temp_df = distribution_df.loc[distribution_df[\"species_lump\"]==i]\n",
        "        temp_lst = []\n",
        "        for j in range(0,len(temp_df)):\n",
        "            temp_lst.append(\n",
        "                [\n",
        "                    float(temp_df.iloc[j][\"x_transect\"]),\n",
        "                    float(temp_df.iloc[j][\"location\"]),\n",
        "                    float(temp_df.iloc[j][\"Mean(z_rock_height)\"])\n",
        "                ]\n",
        "            )\n",
        "        data_dict[i] = temp_lst\n",
        "        del temp_lst\n",
        "        del temp_df\n",
        "\n",
        "\n",
        "    # === Create distribution\n",
        "    scatter_3d = Scatter3D()\n",
        "    for spec in data_dict.keys():\n",
        "        scatter_3d.add(\n",
        "            series_name=spec,\n",
        "            data=data_dict[spec],\n",
        "            xaxis3d_opts=opts.Axis3DOpts(type_=\"value\"),\n",
        "            yaxis3d_opts=opts.Axis3DOpts(type_=\"value\"),\n",
        "            zaxis3d_opts=opts.Axis3DOpts(type_=\"value\"),\n",
        "            grid3d_opts=opts.Grid3DOpts(width=50, height=50, depth=50))\n",
        "    scatter_3d.set_global_opts(legend_opts = opts.LegendOpts(orient='horizontal', pos_top='12%'))\n",
        "\n",
        "    # === Create Grid\n",
        "    final_graph = Grid(init_opts=opts.InitOpts(theme=ThemeType.VINTAGE))\n",
        "    final_graph.add(surface, grid_opts=opts.GridOpts(pos_top=\"25%\"))\n",
        "    final_graph.add(scatter_3d, grid_opts=opts.GridOpts(pos_top=\"25%\"))\n",
        "\n",
        "\n",
        "  else:\n",
        "    # have two sections\n",
        "    # complete section 1\n",
        "    surface_sec_1 = input_df.loc[input_df[\"section\"] == 1]\n",
        "    surface_sec_1 = surface_sec_1[[\"location\",\"x_transect\",\"Mean(z_rock_height)\"]]\n",
        "    data_pair = np.array(surface_sec_1).tolist()\n",
        "    # === Create Surface\n",
        "    surface01 = Surface3D()\n",
        "    surface01.add(\n",
        "        series_name=\"Surface of \"+ site_name,\n",
        "        shading=\"color\",\n",
        "        data=data_pair,\n",
        "        xaxis3d_opts=opts.Axis3DOpts(type_=\"value\",name=\"X Transect\"),\n",
        "        yaxis3d_opts=opts.Axis3DOpts(type_=\"value\",name=\"Y Location\"),\n",
        "        zaxis3d_opts=opts.Axis3DOpts(type_='value',name='Mean(z_rock_height)'),\n",
        "        grid3d_opts=opts.Grid3DOpts(width=100, height=40, depth=100),\n",
        "    )\n",
        "    surface01.set_global_opts(\n",
        "        title_opts=opts.TitleOpts(title=\"Surface Chart - \" + site_name),\n",
        "        visualmap_opts=opts.VisualMapOpts(\n",
        "            dimension=2,\n",
        "            max_=surface_sec_1[\"Mean(z_rock_height)\"].max(),\n",
        "            min_=surface_sec_1[\"Mean(z_rock_height)\"].min(),\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "    # section 2\n",
        "    surface_sec_2 = input_df.loc[input_df[\"section\"] == 2]\n",
        "    surface_sec_2 = surface_sec_2[[\"location\",\"x_transect\",\"Mean(z_rock_height)\"]]\n",
        "    data_pair = np.array(surface_sec_2).tolist()\n",
        "    # === Create Surface\n",
        "    surface02 = Surface3D()\n",
        "    surface02.add(\n",
        "        series_name=\"Surface of \"+ site_name,\n",
        "        shading=\"color\",\n",
        "        data=data_pair,\n",
        "        xaxis3d_opts=opts.Axis3DOpts(type_=\"value\",name=\"X Transect\"),\n",
        "        yaxis3d_opts=opts.Axis3DOpts(type_=\"value\",name=\"Y Location\"),\n",
        "        zaxis3d_opts=opts.Axis3DOpts(type_='value',name='Mean(z_rock_height)'),\n",
        "        grid3d_opts=opts.Grid3DOpts(width=100, height=40, depth=100),\n",
        "    )\n",
        "    surface02.set_global_opts(\n",
        "        visualmap_opts=opts.VisualMapOpts(\n",
        "            dimension=2,\n",
        "            max_=surface_sec_2[\"Mean(z_rock_height)\"].max(),\n",
        "            min_=surface_sec_2[\"Mean(z_rock_height)\"].min(),\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "    # === species data\n",
        "    distribution_df = input_df.copy()\n",
        "    distribution_df.sort_values(by=\"species_lump\")\n",
        "    spec_lst = list(set([i for i in distribution_df[\"species_lump\"]]))\n",
        "    if np.nan in spec_lst:\n",
        "      spec_lst.remove(np.nan)\n",
        "    data_dict = {}\n",
        "    for i in spec_lst:\n",
        "        temp_df = distribution_df.loc[distribution_df[\"species_lump\"]==i]\n",
        "        temp_lst = []\n",
        "        for j in range(0,len(temp_df)):\n",
        "            temp_lst.append(\n",
        "                [\n",
        "                    float(temp_df.iloc[j][\"x_transect\"]),\n",
        "                    float(temp_df.iloc[j][\"location\"]),\n",
        "                    float(temp_df.iloc[j][\"Mean(z_rock_height)\"])\n",
        "                ]\n",
        "            )\n",
        "        data_dict[i] = temp_lst\n",
        "        del temp_lst\n",
        "        del temp_df\n",
        "\n",
        "\n",
        "    # === Create distribution\n",
        "    scatter_3d02 = Scatter3D()\n",
        "    for spec in data_dict.keys():\n",
        "        scatter_3d02.add(\n",
        "            series_name=spec,\n",
        "            data=data_dict[spec],\n",
        "            xaxis3d_opts=opts.Axis3DOpts(type_=\"value\"),\n",
        "            yaxis3d_opts=opts.Axis3DOpts(type_=\"value\"),\n",
        "            zaxis3d_opts=opts.Axis3DOpts(type_=\"value\"),\n",
        "            grid3d_opts=opts.Grid3DOpts(width=50, height=50, depth=50))\n",
        "    scatter_3d02.set_global_opts(legend_opts = opts.LegendOpts(orient='horizontal', pos_top='12%'))\n",
        "\n",
        "\n",
        "    # === Create Grid\n",
        "    final_graph = Grid(init_opts=opts.InitOpts(theme=ThemeType.VINTAGE))\n",
        "    final_graph.add(surface01, grid_opts=opts.GridOpts(pos_top=\"25%\"))\n",
        "    final_graph.add(surface02, grid_opts=opts.GridOpts(pos_top=\"25%\"))\n",
        "    final_graph.add(scatter_3d02, grid_opts=opts.GridOpts(pos_top=\"25%\"))\n",
        "\n",
        "  # === Return Grid\n",
        "  return final_graph"
      ],
      "metadata": {
        "id": "qMYS6-DcNt5k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diagram - Themeriver\n",
        "- Display the percentage change of the species with years"
      ],
      "metadata": {
        "id": "BsDK56JQuZVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def themeriver(site_df, site_name):\n",
        "  # Calculate total percent_cover for each species over the years\n",
        "  site_df[\"total_percent_cover\"] = site_df.groupby([\"year\", \"species_lump\"])[\"percent_cover\"].transform(\"sum\")\n",
        "  site_df = site_df.loc[site_df[\"species_lump\"] != \"Other Species\"]\n",
        "  # Prepare data for the river chart\n",
        "  data_copy = []\n",
        "  species_list = site_df[\"species_lump\"].unique()\n",
        "  for species in species_list:\n",
        "      species_data = site_df[site_df[\"species_lump\"] == species]\n",
        "      total_percent_species = species_data[\"percent_cover\"].sum()\n",
        "\n",
        "      data_copy.extend([\n",
        "          [str(year), round(float(species_data[species_data[\"year\"] == year][\"percent_cover\"].sum()),10), species]\n",
        "          for year in species_data[\"year\"].unique()\n",
        "      ])\n",
        "\n",
        "  # River Chart\n",
        "  c_ThemeRiver = ThemeRiver(init_opts=opts.InitOpts(theme=ThemeType.VINTAGE))  # Use LIGHT theme for a white background\n",
        "  c_ThemeRiver.add(\n",
        "      series_name=list(species_list),\n",
        "      data=data_copy,\n",
        "      singleaxis_opts=opts.SingleAxisOpts(\n",
        "          pos_top=\"90\", pos_bottom=\"30\", type_=\"time\",\n",
        "          splitline_opts=opts.SplitLineOpts(is_show=True),\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  # Set options\n",
        "  c_ThemeRiver.set_global_opts(\n",
        "      tooltip_opts=opts.TooltipOpts(trigger=\"axis\", axis_pointer_type=\"line\"),\n",
        "      title_opts=opts.TitleOpts(title=\"River Chart - Change of Species in \" + site_name),\n",
        "      legend_opts=opts.LegendOpts(orient='horizontal', pos_top=\"7%\"),\n",
        "  )\n",
        "  c_ThemeRiver.set_series_opts(label_opts=opts.LabelOpts(is_show=0))\n",
        "  c_ThemeRiver.chart_id = \"2\"\n",
        "\n",
        "\n",
        "  # Add to grid\n",
        "  graph = Grid(init_opts=opts.InitOpts(theme=ThemeType.VINTAGE))  # Use LIGHT theme for a white background\n",
        "  graph.add(c_ThemeRiver, grid_opts=opts.GridOpts(pos_top=\"35%\"))\n",
        "\n",
        "  # Return River Chart\n",
        "  return graph"
      ],
      "metadata": {
        "id": "hu1YjIjyE8wG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diagram - Pie Chart\n",
        "- Display the latest year's species % at the site"
      ],
      "metadata": {
        "id": "ORYxBtMKu2lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pie(site_df, site_name):\n",
        "  # Find the most recent year in the DataFrame\n",
        "  most_recent_year = site_df['year'].max()\n",
        "  # Filter the DataFrame for the most recent year\n",
        "  recent_year_data = site_df[site_df['year'] == most_recent_year]\n",
        "  # Calculate total percent_cover for each species for the most recent year\n",
        "  total_percent_cover = recent_year_data.groupby(\"species_lump\")[\"percent_cover\"].sum()\n",
        "  # Data Preparing\n",
        "  data_copy = pd.DataFrame({\n",
        "      'species_lump': total_percent_cover.index,\n",
        "      'total_percent_cover': total_percent_cover.values\n",
        "  })\n",
        "  value = [round(i, 2) for i in data_copy[\"total_percent_cover\"]]\n",
        "  attr = [i for i in data_copy[\"species_lump\"]]\n",
        "\n",
        "\n",
        "  # Pie Chart\n",
        "  pie = Pie(init_opts=opts.InitOpts(theme=ThemeType.VINTAGE))  # Use LIGHT theme for a white background\n",
        "  pie.add(series_name=\"\",\n",
        "          data_pair=[list(z) for z in zip(attr, value)],\n",
        "          radius=[\"30%\", \"75%\"],\n",
        "          rosetype=\"radius\",\n",
        "          label_opts=opts.LabelOpts(is_show=True),\n",
        "          is_legend_hover_link=True\n",
        "          )\n",
        "  pie.set_global_opts(\n",
        "      title_opts=opts.TitleOpts(title=f\"Pie Chart - {most_recent_year} Species in {site_name}\"),\n",
        "      legend_opts=opts.LegendOpts(is_show=0)\n",
        "  )\n",
        "\n",
        "  # Return Pie Chart\n",
        "  return pie"
      ],
      "metadata": {
        "id": "oF5LBvXV0F17"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diagram - Bar Chart\n",
        "- Display the percentage species coverage"
      ],
      "metadata": {
        "id": "bLwqwVPCvPH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bar(site_df, site_name):\n",
        "  # Calculate the total percent_cover for each species over the years\n",
        "  site_df[\"total_percent_cover\"] = site_df.groupby([\"year\", \"species_lump\"])[\"percent_cover\"].transform(\"sum\")\n",
        "  # Group by year and species, then sum the percentages\n",
        "  species_percentages = site_df.groupby(['year', 'species_lump'])['percent_cover'].sum().reset_index()\n",
        "  # Pivot the DataFrame to have species as columns and years as indices\n",
        "  pivot_df = species_percentages.pivot_table(index='year', columns='species_lump', values='percent_cover', aggfunc='sum').fillna(0)\n",
        "\n",
        "  x_data = [str(year) for year in sorted(site_df['year'].unique())]\n",
        "  y_data = {}\n",
        "  # Iterate over columns (species) and extract data for each species\n",
        "  for species in pivot_df.columns:\n",
        "      y_data[species] = pivot_df[species].tolist()\n",
        "\n",
        "\n",
        "  # Bar Chart\n",
        "  bar = Bar(init_opts=opts.InitOpts(theme=ThemeType.VINTAGE))  # Use LIGHT theme for a white background\n",
        "  bar.add_xaxis(x_data)\n",
        "  bar.set_global_opts(\n",
        "      title_opts=opts.TitleOpts(title=\"Bar Chart - Percent Species Coverage in \" + site_name),\n",
        "      datazoom_opts=[opts.DataZoomOpts(), opts.DataZoomOpts(type_=\"inside\")],\n",
        "      legend_opts=opts.LegendOpts(pos_top=\"7%\"),\n",
        "      yaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(formatter=\"{value}%\"))  # Add % to y-axis labels\n",
        "  )\n",
        "\n",
        "  for species, data in y_data.items():\n",
        "      bar.add_yaxis(species, [round(element,2) for element in data])\n",
        "\n",
        "\n",
        "  # Add to grid\n",
        "  graph = Grid(init_opts=opts.InitOpts(theme=ThemeType.VINTAGE))  # Use LIGHT theme for a white background\n",
        "  graph.add(bar, grid_opts=opts.GridOpts(pos_top=\"30%\"))\n",
        "\n",
        "  # Return grid\n",
        "  return graph"
      ],
      "metadata": {
        "id": "FXSWlxEQ5TIn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - HTML Rendering Function"
      ],
      "metadata": {
        "id": "-5SRIDeoxtjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_html_styling(html_file_path):\n",
        "  # Open the HTML file and apply styling\n",
        "  with open(html_file_path, 'r+', encoding=\"utf8\") as html:\n",
        "      html_bf = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "      # Add styling here\n",
        "      body = html_bf.find(\"body\")\n",
        "      body[\"style\"] = \"background-color:#fef8ef;\"\n",
        "      html_new = str(html_bf)\n",
        "      html.seek(0, 0)\n",
        "      html.truncate()\n",
        "      html.write(html_new)\n",
        "      html.close()"
      ],
      "metadata": {
        "id": "ZB5Rf83VF71O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_html_for_site(site_name, surface_chart, river_chart, pie_chart, bar_chart):\n",
        "  # Create a Page layout and add the River Chart to it\n",
        "  page_layout = Page(layout=Page.SimplePageLayout).add(\n",
        "      surface_chart,\n",
        "      river_chart,\n",
        "      pie_chart,\n",
        "      bar_chart\n",
        "  )\n",
        "\n",
        "  # Render the Page and save it as an HTML file\n",
        "  html_file_path = f\"{site_name}_visualization.html\"\n",
        "  page_layout.render(html_file_path)\n",
        "\n",
        "  # Apply styling to the HTML file\n",
        "  apply_html_styling(html_file_path)\n",
        "\n",
        "  # Display the path to the generated HTML file\n",
        "  print(f\"HTML file for {site_name} visualization saved at: {html_file_path}\")"
      ],
      "metadata": {
        "id": "uyb3HWFHsyGy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Iterations to render and generate html"
      ],
      "metadata": {
        "id": "rG1GrQdgukNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for site_name, site_df in grouped_data:\n",
        "  surface_chart = surface(elevation_df, species_df, site_name)\n",
        "  river_chart = themeriver(site_df, site_name)\n",
        "  pie_chart = pie(site_df, site_name)\n",
        "  bar_chart = bar(site_df, site_name)\n",
        "  generate_html_for_site(site_name, surface_chart, river_chart, pie_chart, bar_chart)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guH9zbIsr6y7",
        "outputId": "a5bc85d4-981f-427f-c0fb-926ea1718285"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HTML file for Bob Creek visualization saved at: Bob Creek_visualization.html\n",
            "HTML file for Bodega visualization saved at: Bodega_visualization.html\n",
            "HTML file for Buck Gully South visualization saved at: Buck Gully South_visualization.html\n",
            "HTML file for Cape Arago visualization saved at: Cape Arago_visualization.html\n",
            "HTML file for Fogarty Creek visualization saved at: Fogarty Creek_visualization.html\n",
            "HTML file for Heisler Park visualization saved at: Heisler Park_visualization.html\n",
            "HTML file for Point Fermin visualization saved at: Point Fermin_visualization.html\n",
            "HTML file for White Point visualization saved at: White Point_visualization.html\n"
          ]
        }
      ]
    }
  ]
}